project: common-lit-eval-stu-summerize
name: experiment-tracking-Common_Lit_Evaluate_Student_Summaries
wandb:
  WANDB_API_KEY: WANDB_API_KEY
  entity: baolocpham
  project: common-lit-eval-stu-summerize
  name: common-lit-eval-stu-summerize
  group: common-lit-eval-stu-summerize_training
  job_type: Train_Supervised
parameters:
  root_data_dir: "./data"
  grade_data_dir: "./data"
  n_fold: 4
  save_model_dir: "./outputs"
  preprocess_text: False
  debug: False
  
  train_stage_1:
    select: "base"
    model_name: "microsoft/deberta-v3-{select}"
    only_model_name: "deberta-v3-{select}"
    output_model_dir: "./"
    output_model_name: "deberta-v3-{select}_Fold_{fold}.pth"
    tokenizer: null
    accum_iter: 16
    fold: 4
    split: 5
    seed: 42
    batch_size: 2
    max_len: 32
    max_len_char_title: null
    max_len_char_question: null
    max_len_char_prompt_text: null
    full_text: "title,question,prompt-text,text"
    num_epoch: 5
    T_max: 500
    loss: ""
    scheduler: "CosineAnnealingLR"
    min_lr: 1e-6
    freezing: False
    n_layers_freezing: 0
    strategy: "GroupKFold"
    pooling: "GemText"
    weight_decay: 1e-2
    encoder_lr: 1e-5
    decoder_lr: 1e-5
    eps: 1e-6
    betas: (0.9, 0.999)

  inference_stage_1:
    select: "base"
    model_name: "microsoft/deberta-v3-{select}"
    only_model_name: "deberta-v3-{select}"
    n_fold: 4
    fold_to_inference: 0
    batch_size: 32
    freezing: False
    max_len: 32
    max_len_char_title: null
    max_len_char_question: null
    max_len_char_prompt_text: null
    full_text: "title,question,prompt-text,text"
    pooling: "GemText"
    load_model_dir: ""
    output_dir: ""
    have_next_stage: False
    output_file: "stage_1_output.csv"

  train_stage_2:    
    # input_dir: "./"
    # input_file: "stage_1_output.csv"
    
    output_dir: "./"
    output_file: "stage_2_output.csv"
    output_model_dir: "./"
    output_model_name: "lgbm_{target}_{fold}.pkl"
    strategy: "GroupKFold"
    use_optuna: False
    boosting_type: 'gbdt'
    random_state: 42
    objective: 'regression'
    metric: 'rmse'
    learning_rate: 0.048
    max_depth: 3
    lambda_l1: 0.0
    lambda_l2: 0.011  

  inference_stage_2:    
    input_dir: "./"
    input_file: "stage_1_output.csv"
    output_dir: "./"
    output_file: "submission.csv"
    input_model_dir: "./"
    input_model_name: "lgbm_{target}_{fold}.pkl"
    boosting_type: 'gbdt'
    random_state: 42
    objective: 'regression'
    metric: 'rmse'
    learning_rate: 0.048
    max_depth: 3
    lambda_l1: 0.0
    lambda_l2: 0.011
    have_stage_1: False
